{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tslearn.metrics import dtw\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "tickers = ['XLF', 'XLU', 'QQQ', 'SPY', 'XLP', 'EWZ', 'EWH', 'XLY', 'XLE']\n",
    "tickers = ['SPY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takes very long, focus on SPY first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XLF_2019 Train-to-Train:   0%|          | 2/1243 [00:41<7:12:35, 20.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m distances \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, train_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):  \u001b[38;5;66;03m# Only calculate for the upper triangle of train set\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     distance, _ \u001b[38;5;241m=\u001b[39m \u001b[43mfastdtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Flatten if needed for DTW\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     distances\u001b[38;5;241m.\u001b[39mappend((distance, j))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Sort the distances and get the k most similar windows for train-to-train\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\65981\\OneDrive\\Documents\\GitHub\\Pattern_Window_Forecasting\\.venv\\lib\\site-packages\\fastdtw\\fastdtw.py:53\u001b[0m, in \u001b[0;36mfastdtw\u001b[1;34m(x, y, radius, dist)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' return the approximate distance between 2 time series with O(N)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    time and memory complexity\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    (2.0, [(0, 0), (1, 0), (2, 1), (3, 2), (4, 2)])\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     52\u001b[0m x, y, dist \u001b[38;5;241m=\u001b[39m __prep_inputs(x, y, dist)\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__fastdtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\65981\\OneDrive\\Documents\\GitHub\\Pattern_Window_Forecasting\\.venv\\lib\\site-packages\\fastdtw\\fastdtw.py:75\u001b[0m, in \u001b[0;36m__fastdtw\u001b[1;34m(x, y, radius, dist)\u001b[0m\n\u001b[0;32m     72\u001b[0m distance, path \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m     73\u001b[0m     __fastdtw(x_shrinked, y_shrinked, radius\u001b[38;5;241m=\u001b[39mradius, dist\u001b[38;5;241m=\u001b[39mdist)\n\u001b[0;32m     74\u001b[0m window \u001b[38;5;241m=\u001b[39m __expand_window(path, \u001b[38;5;28mlen\u001b[39m(x), \u001b[38;5;28mlen\u001b[39m(y), radius)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__dtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\65981\\OneDrive\\Documents\\GitHub\\Pattern_Window_Forecasting\\.venv\\lib\\site-packages\\fastdtw\\fastdtw.py:142\u001b[0m, in \u001b[0;36m__dtw\u001b[1;34m(x, y, window, dist)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m window:\n\u001b[0;32m    141\u001b[0m     dt \u001b[38;5;241m=\u001b[39m dist(x[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y[j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 142\u001b[0m     D[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((D[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mdt, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j), (\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mdt, i, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    143\u001b[0m                   (D[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mdt, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    144\u001b[0m path \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    145\u001b[0m i, j \u001b[38;5;241m=\u001b[39m len_x, len_y\n",
      "File \u001b[1;32mc:\\Users\\65981\\OneDrive\\Documents\\GitHub\\Pattern_Window_Forecasting\\.venv\\lib\\site-packages\\fastdtw\\fastdtw.py:138\u001b[0m, in \u001b[0;36m__dtw.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m     window \u001b[38;5;241m=\u001b[39m [(i, j) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(len_x) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(len_y)]\n\u001b[0;32m    137\u001b[0m window \u001b[38;5;241m=\u001b[39m ((i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m window)\n\u001b[1;32m--> 138\u001b[0m D \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: (\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,))\n\u001b[0;32m    139\u001b[0m D[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m window:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 100  # Number of most similar training windows\n",
    "\n",
    "for ticker in tickers:\n",
    "    for year in range(2019, 2021):\n",
    "        # Read in data\n",
    "        df = pd.read_csv(f'./data/test_years/{ticker}_{year}.csv')\n",
    "\n",
    "        # Convert string representations of lists back to Python lists\n",
    "        for col in df.columns:\n",
    "            if col not in ['Date', 'Label']:\n",
    "                df[col] = df[col].apply(ast.literal_eval)\n",
    "\n",
    "        # Split into training (year t-5 to t-1) and testing (year t) sets\n",
    "        train_df = df[df['Date'].str[:4].astype(int) < year]\n",
    "        test_df = df[df['Date'].str[:4].astype(int) == year]\n",
    "\n",
    "        # Remove 'Label' and 'Date' columns\n",
    "        train_features = train_df.drop(columns=['Label', 'Date']).values\n",
    "        test_features = test_df.drop(columns=['Label', 'Date']).values\n",
    "\n",
    "        # Convert features to numpy arrays (15x15 matrices)\n",
    "        train_features = np.array([np.stack(row) for row in train_features])  # Shape: (train_samples, 15, 15)\n",
    "        test_features = np.array([np.stack(row) for row in test_features])    # Shape: (test_samples, 15, 15)\n",
    "\n",
    "        # Initialize the result\n",
    "        most_similar_indices_train = []\n",
    "        most_similar_indices_test_to_train = []\n",
    "\n",
    "        # Compute MDTW distances for train-to-train\n",
    "        for i in tqdm(range(train_features.shape[0]), desc=f\"Processing {ticker}_{year} Train-to-Train\"):\n",
    "            distances = []\n",
    "\n",
    "            for j in range(i + 1, train_features.shape[0]):  # Only calculate for the upper triangle of train set\n",
    "                distance, _ = fastdtw(train_features[i].flatten(), train_features[j].flatten())  # Flatten if needed for DTW\n",
    "                distances.append((distance, j))\n",
    "\n",
    "            # Sort the distances and get the k most similar windows for train-to-train\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            most_similar = [index for _, index in distances[:k]]\n",
    "\n",
    "            # Store the k most similar windows (train-to-train)\n",
    "            most_similar_indices_train.append(most_similar)\n",
    "\n",
    "        # Compute MDTW distances for test-to-train\n",
    "        for i in tqdm(range(test_features.shape[0]), desc=f\"Processing {ticker}_{year} Test-to-Train\"):\n",
    "            distances = []\n",
    "\n",
    "            for j in range(train_features.shape[0]):  # Compare with all train samples\n",
    "                distance, _ = fastdtw(test_features[i].flatten(), train_features[j].flatten())  # Flatten if needed for DTW\n",
    "                distances.append((distance, j))\n",
    "\n",
    "            # Sort the distances and get the k most similar windows for test-to-train\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            most_similar = [index for _, index in distances[:k]]\n",
    "\n",
    "            # Store the k most similar windows (test-to-train)\n",
    "            most_similar_indices_test_to_train.append(most_similar)\n",
    "\n",
    "        # Combine both results in the DataFrame (train-to-train and test-to-train)\n",
    "        train_df_copy = train_df.copy()\n",
    "        test_df_copy = test_df.copy()\n",
    "\n",
    "        train_df_copy['Most_Similar_Windows'] = most_similar_indices_train\n",
    "        test_df_copy['Most_Similar_Windows'] = most_similar_indices_test_to_train\n",
    "\n",
    "        # Combine train and test data back into a single DataFrame\n",
    "        df_combined = pd.concat([train_df_copy, test_df_copy], axis=0)\n",
    "\n",
    "        # Save the updated DataFrame with the most similar windows information\n",
    "        df_combined.to_csv(f'./data/mdtw/{ticker}_{year}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
