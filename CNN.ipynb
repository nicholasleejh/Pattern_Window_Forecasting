{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "tickers = ['SPY', 'IWM', 'DIA']\n",
    "VERSION_NAME = 'widerATR_20day'\n",
    "os.makedirs(f'./results_{VERSION_NAME}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_image(input_df):\n",
    "    df = input_df.copy()\n",
    "    \n",
    "    # Define indicator structure\n",
    "    INDICATOR_ORDER = [\n",
    "        'SMA', 'EMA', 'WMA', 'HMA', 'TEMA',\n",
    "        'PSAR', 'DMI', 'CMFI',\n",
    "        'RSI', 'Williams_%R', 'CMO', 'ROC',\n",
    "        'MACD', 'PPO', 'CCI'\n",
    "    ]\n",
    "    \n",
    "    # Pre-allocate image array (optimized memory layout)\n",
    "    images = np.empty((len(df), 15, 15), dtype=np.float32)\n",
    "    \n",
    "    # 3. Fill array using vectorized operations (faster than loops)\n",
    "    for i, indicator in enumerate(INDICATOR_ORDER):\n",
    "        for j, n in enumerate(range(6, 21)):\n",
    "            images[:, i, j] = df[f'{indicator}_{n}'].values\n",
    "    \n",
    "    # 4. Create output DataFrame (memory efficient)\n",
    "    result_df = pd.DataFrame({\n",
    "        'Date': df['Date'].values,\n",
    "        'Close': df['Close'].values,\n",
    "        'Label': df['Label'].values,\n",
    "        'Image': list(images)  # Store arrays directly\n",
    "    })\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, year):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    train = df[df['Date'].dt.year < year-1]\n",
    "    val = df[df['Date'].dt.year == year-1]\n",
    "    test = df[df['Date'].dt.year >= year]\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare Data Loaders\n",
    "def prepare_data(df):\n",
    "    \"\"\"Convert DataFrame to CNN-ready arrays\"\"\"\n",
    "    X = np.stack(df['Image'].values)  # Shape: (n_samples, 15, 15)\n",
    "    X = np.expand_dims(X, -1)  # Add channel dimension (15,15,1)\n",
    "    y = to_categorical(df['Label'])\n",
    "    return X, y\n",
    "\n",
    "# 2. Define Model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Input(shape=(15, 15, 1)),                    # [15×15×1] indicator grid\n",
    "        Conv2D(32, (3,3), activation='relu'),        # 32 filters, 3×3 kernels\n",
    "        Conv2D(64, (3,3), activation='relu'),        # 64 filters, 3×3 kernels\n",
    "        MaxPooling2D((2,2)),                         # Downsampling to 7×7×64\n",
    "        Dropout(0.25),                               # Spatial dropout\n",
    "        Flatten(),                                   # Vectorize to 3136 elements\n",
    "        Dense(128, activation='relu'),               # Fully-connected layer\n",
    "        Dropout(0.5),                                # Feature dropout\n",
    "        Dense(3, activation='softmax')               # Probabilistic outputs\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 3. Training Loop\n",
    "results = []\n",
    "for ticker in tickers:\n",
    "    for year in range(2019, 2024):\n",
    "        print(f\"\\nProcessing {ticker} {year}-{year+1}\")\n",
    "        \n",
    "        # Load and split data\n",
    "        df = pd.read_csv(f'./data/normalised/{ticker}_{year}_{year+1}.csv')\n",
    "        df = form_image(df)\n",
    "        train, val, test = train_val_test_split(df, year)\n",
    "        \n",
    "        # Prepare datasets\n",
    "        X_train, y_train = prepare_data(train)\n",
    "        X_val, y_val = prepare_data(val)\n",
    "        X_test, y_test = prepare_data(test)\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_model()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Evaluate and get predictions\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        y_pred = model.predict(X_test, verbose=0)\n",
    "        \n",
    "        # Get predictions (will output 0/1 matching your labels)\n",
    "        test = test.copy()  # Avoid SettingWithCopyWarning\n",
    "        test['Prediction'] = np.argmax(model.predict(X_test), axis=1)\n",
    "        test['Prediction_Prob'] = np.max(y_pred, axis=1)  # Store confidence\n",
    "\n",
    "        # Drop Image\n",
    "        test = test.drop(columns=['Image'])\n",
    "\n",
    "        test.to_csv(f'./results_{VERSION_NAME}/{ticker}_{year}_{year+1}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
